\documentclass[a4paper, 12pt]{article}


\usepackage{/Users/zhengz/Desktop/Math/Workspace/Homework1/homework}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%Header-Make sure you update this information!!!!
\noindent
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\large\textbf{Zhengdong Zhang} \hfill \textbf{Homework - Week 5}   \\
Email: zhengz@uoregon.edu \hfill ID: 952091294 \\
\normalsize Course: MATH 648 - Abstract Algebra  \hfill Term: Winter 2025\\
Instructor: Professor Arkady Berenstein \hfill Due Date: $12^{th}$ February, 2025 \\
\noindent\rule{7in}{2.8pt}
\setstretch{1.1}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Exercise 16.3.2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}{16.3.2}
Compute \(J(\mathbb{C}[x])\) and \(J(\mathbb{C}[[x]])\).
\end{problem}
\begin{solution}
We know that \(\mathbb{C}[x]\) is a PID. For \(f,g\in \mathbb{C}[x]\), we know that \((f)\supset (g)\) if and only if \(f|g\). Since \(\mathbb{C}\) is 
algebraically closed, every polynomial in \(\mathbb{C}[x]\) can be written as a product of linear terms. So the maximal ideals in \(\mathbb{C}[x]\) are of the form 
\((x-a)\) where \(a\in \mathbb{C}\) is a complex number. So the Jacobson radical 
\[J(\mathbb{C}[x])=\bigcap_{a\in \mathbb{C}} (x-a).\]
Note that for \(a\neq b\in \mathbb{C}\), the intersection 
\[(x-a)\cap(x-b)=((x-a)(x-b))\]
So \(J(\mathbb{C}[x])\) is generated by the product of all linear terms \(x-c\) where \(c\in \mathbb{C}\). Because \(\mathbb{C}\) has infinitely many elements, so this is impossible as every polynomial only has finitely many terms. So \(J(\mathbb{C}[x])=(0)\).

For \(\mathbb{C}[[x]]\), we first prove the following:
\begin{claim}
Any proper ideal in \(\mathbb{C}[[x]]\) must be of the form \((x^p)\) for \(p\geq 1\).
\end{claim}
\begin{claimproof}
Write every element in \(\mathbb{C}[[x]]\) as 
\[t=\sum_{k=0}^\infty a_k x^k. \]
Suppose \(a_0\neq 0\). We are going to show that \(t\) is invertible in \(\mathbb{C}[[x]]\). We define an element \(s=\sum_{j=0}^\infty b_jx^j\) inductively as follows: 
\begin{align*}
    b_0a_0&=1,\\
    b_1a_0+b_0a_1&=0,\\ 
    b_2a_0+b_1a_1+b_0a_2&=0,\\ 
    \cdots
\end{align*}
For each \(j\geq 1\), we can obtain \(b_j\) by solving a linear equation 
\[b_ja_0+b_{j-1}a_1+\cdots+b_0a_j=0.\]
This defines an element \(s=\sum_{j=0}^\infty b_jx^j\in \mathbb{C}[[x]]\), and we have 
\begin{align*}
    st&=(\sum_{k=0}^\infty a_kx^k)(\sum_{j=0}^\infty b_jx^j)\\ 
      &=a_0b_0+(b_1a_0+b_0a_1)x+\cdots+(b_ja_0+b_{j-1}a_1+\cdots+b_0a_j)x^j+\cdots\\ 
      &=1.
\end{align*}
This proves that for \(a_0\neq 0\), \(m=\sum_{k=0}^\infty a_kx^k\) is a unit in \(\mathbb{C}[[x]]\). Let \(I\subset \mathbb{C}[[x]]\) be a proper ideal. \(I\) does not contain any unit, so for 
any \(\sum_{k=0}^\infty a_kx^k\in I\), \(a_0=0\). Define 
\[p:=\min \left\{ p \in \mathbb{Z}_{>0}\mid \sum_{k=0}a_kx^k\in I\ \ \text{and}\ \ a_p\neq 0\right\}.\]
We know \(p\geq 1\) since \(I\) cannot contain units. Note that \(x^p\) divides all the elements in \(I\) and by definition, there exists an element \(\sum_{k=0}^\infty a_kx^k\in I\) such that \(a_0=\cdots=a_{p-1}=0\) and \(a_p\neq 0\), this element 
can be written as \(x^p(a_p+a_{p+1}x+\cdots)\) where \(a_p+a_{p+1}x+\cdots\) is invertible, so we have proved \(I=(x^p)\). 
\end{claimproof}

By the claim, we know that any proper ideal in \(\mathbb{C}[[x]]\) must be of the form \((x^p)\) for \(p\geq 1\). And \((x^p)\supset (x^q)\) if and only if \(p\leq q\). So \(\mathbb{C}[[x]]\) has only one maximal ideal \((x)\), and the Jacobson radical 
\(J(\mathbb{C}[[x]])=(x)\).
\end{solution}

\noindent\rule{7in}{2.8pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Exercise 16.3.3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}{16.3.3}
True or false? \(J(R_1\times \cdots\times R_n)=J(R_1)\times \cdots\times J(R_n)\).
\end{problem}
\begin{solution}
This is true. We only need to show that \(J(R_1\times R_2)=J(R_1)\times J(R_2)\) and obtain the rest by induction. Let \(I\subset R_1\times R_2\) be an ideal. Let \((a,b)\in I\) and \((r_1,r_2)\in R_1\times R_2\), we know that 
\((r_1a,r_2b)\in I\). Consider two projections \(\pi_1:R_1\times R_2\rightarrow R_1\) and \(\pi_2:R_1\times R_2\rightarrow R_2\). The previous discussion tells us that \(\pi_1(I)\) is an ideal in \(R_1\) and \(\pi_2(I)\) is an ideal 
in \(R_2\). So \(I\) must be of the form 
\[\left\{ (a,b)\in R_1\times R_2\mid a\in I_1,b\in I_2 \right\}\]
where \(I_1\) is an ideal in \(R_1\) and \(I_2\) is an ideal in \(R_2\). So the maximal ideals in \(R_1\times R_2\) can only be of the following two forms: \(m_1\times R_2\) or \(R_1\times m_2\), where \(m_1\) is a maximal ideal in \(R_1\) and 
\(m_2\) is a maximal ideal in \(R_2\). So the Jacobson radical 
\begin{align*}
J(R_1\times R_2)&=(\bigcap_{m_1\subset R_1}m_1\times R_2)\bigcap(\bigcap_{m_2\subset R_2}R_1\times m_2)\\ 
                &=\bigcap_{m_1\subset R_1}\bigcap_{m_2\subset R_2}m_1\times m_2\\ 
                &=(\bigcap_{m_1\subset R_1}m_1)\times (\bigcap_{m_2\subset R_2}m_2)\\ 
                &=J(R_1)\times J(R_2).
\end{align*}
\end{solution}

\noindent\rule{7in}{2.8pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Exercise 16.3.9
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}{16.3.9}
Prove that \(J(R)\) contains no non-zero idempotent.
\end{problem}
\begin{solution}
Suppose \(e\in J(R)\) is a non-zero idempotent. By Proposition 16.3.7, we know there exists a left inverse \(v\in R\) such that \(v(1-e)=1\). By Proposition 16.3.8, \(1+e\) is a unit in \(R\), so there exists \(u\in R\) such that 
\(u(1+e)=(1+e)u=1\). Note that since \(e\) is an idempotent, \((1-e)(1+e)=1-e^2=1-e\). So we have 
\[1=u(1+e)=uv(1-e)(1+e)=uv(1-e)=u.\]
This implies \(1+e=1\), so \(e=1\in J(R)\), which means \(J(R)=R\). A contradiction.
\end{solution}

\noindent\rule{7in}{2.8pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Exercise 16.3.14
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}{16.3.14}
True or false? If \(r\in R\) is a nilpotent element then the left ideal of \(R\) generated by \(r\) is nilpotent.
\end{problem}
\begin{solution}
This is false. Consider the matrix ring \(M_2(\mathbb{R})\) over \(\mathbb{R}\). \(A=\begin{pmatrix}
    1&-1\\ 
    1&-1
\end{pmatrix}\) is a nilpotent element in \(M_2(\mathbb{R})\) because 
\[A^2=\begin{pmatrix}
    1&-1\\ 
    1&-1
\end{pmatrix}\begin{pmatrix}
    1&-1\\ 
    1&-1
\end{pmatrix}=\begin{pmatrix}
    0&0\\ 
    0&0
\end{pmatrix}.\]
Consider the ideal \(I\) generated by \(A\). Note that 
\[B=\begin{pmatrix}
    1&0\\ 
    1&0
\end{pmatrix}A=\begin{pmatrix}
    1&0\\ 
    -1&0
\end{pmatrix}\begin{pmatrix}
    1&-1\\ 
    1&-1
\end{pmatrix}=\begin{pmatrix}
    1&-1\\ 
    -1&1
\end{pmatrix}\in I.\]
\begin{claim}
For any \(n\geq 1\), we have 
\[B^n=\begin{pmatrix}
    2^{n-1}&-2^{n-1}\\ 
    -2^{n-1}&2^{n-1}
\end{pmatrix}\]
\end{claim}
\begin{claimproof}
We prove this by indcution on \(n\). \(n=1\) is obvious. For \(n\geq 2\), suppose we have already know 
\[B^{n-1}=\begin{pmatrix}
    2^{n-2}&-2^{n-2}\\ 
    -2^{n-2}&2^{n-2}
\end{pmatrix}.\]
Then 
\[B^n=B\cdot B^{n-1}=\begin{pmatrix}
    1&-1\\ 
    -1&1
\end{pmatrix}\begin{pmatrix}
    2^{n-2}&-2^{n-2}\\ 
    -2^{n-2}&2^{n-2}
\end{pmatrix}=\begin{pmatrix}
    2^{n-1}&-2^{n-1}\\ 
    -2^{n-1}&2^{n-1}
\end{pmatrix}.\]
We are done.
\end{claimproof}

The claim implies that for any \(n\geq 1\), \(B^n\neq 0\). So the ideal \(I\) is not nilpotent.
\end{solution}

\noindent\rule{7in}{2.8pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Exercise 16.3.18
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}{16.3.18}
Calculate the Jacobson radical of the ring \(\mathbb{Z}/ m \mathbb{Z}\).
\end{problem}
\begin{solution}
Suppose \(m=p_1^{n_1}\cdots p_k^{n_k}\) where \(2\leq p_1\leq p_2\leq \cdots\leq p_k\) are primes in \(\mathbb{Z}\) and \(n_1,n_2,\ldots,n_k\geq 1\) are positive integers. This decomposition is unique since \(\mathbb{Z}\) is a UFD. By 
Chinese Remainder Theorem, we have 
\[\mathbb{Z}/m \mathbb{Z}\cong \mathbb{Z}/p_1^{n_1} \mathbb{Z}\times \cdots\times \mathbb{Z}/p_k^{n_k}\mathbb{Z}.\]
We have proved in Exercise 16.3.3 that 
\[J(\mathbb{Z}/m \mathbb{Z})=J(\mathbb{Z}/p_1^{n_1}\mathbb{Z})\times \cdots\times J(\mathbb{Z}/p_k^{n_k} \mathbb{Z}).\]
Next, we are going to determine the Jacobson radical for the ring \(\mathbb{Z}/p^n \mathbb{Z}\) where \(p\) is prime number and \(n\geq 1\) is a positive integer. 
\begin{claim}
\(J(\mathbb{Z}/p^n \mathbb{Z})=(p)=p \mathbb{Z}/p^n \mathbb{Z}\cong \mathbb{Z}/p^{n-1}\mathbb{Z}\).
\end{claim}
\begin{claimproof}
\(\mathbb{Z}/p^n \mathbb{Z}\) is commutative, so for any \(pa\in \mathbb{Z}/p^n \mathbb{Z}\), we have 
\[(pa)^n=p^na^n=0.\]
This means \(pa\) is nilpotent. By Corollary 16.3.16, \(J(\mathbb{Z}/p^n \mathbb{Z})\) must contain all elements of the form \(pa\), namely \((p)\subset J(\mathbb{Z}/p^n \mathbb{Z})\). Moreover, \(p\) being a prime number tells us that 
\((p)\) is a maximal ideal in \(\mathbb{Z}/p^n \mathbb{Z}\), so \(J(\mathbb{Z}/p^n \mathbb{Z})\) as the intersection of all maximal ideals must be contained in \((p)\). This proves that 
 \[J(\mathbb{Z}/p^n \mathbb{Z})=(p)=p \mathbb{Z}/p^n \mathbb{Z}\cong \mathbb{Z}/p^{n-1}\mathbb{Z}.\]
\end{claimproof}

From the claim, the Jacobson radical 
\[J(\mathbb{Z}/m \mathbb{Z})=\mathbb{Z}/p_1^{n_1-1}\mathbb{Z}\times \cdots\times \mathbb{Z}/p_k^{n_k-1}\mathbb{Z}.\]
\end{solution}

\noindent\rule{7in}{2.8pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Exercise 16.3.19
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}{16.3.19}
let \(A\) be the algebra of lower triangular \(n\times n\) matrices over a field \(\mathbb{F}\). Then \(J(A)\) is the subset of matrices in \(A\) with all diagonal 
entries zero.
\end{problem}
\begin{solution}
Let \(I\subset A\) be the subset of all matrices in \(A\) with  diagonal entries zero. For \(M=(M_{ij})_{1\leq i,j\leq n}\in A\) and \(N=(N_{ij})_{1\leq i,j\leq n}\in I\), for any \(1\leq i\leq n\), we have 
\[(MN)_{ii}=\sum_{k=1}^{n}M_{ik}N_{ki}.\]
\(M\) being a lower triangular matrix implies that for \(k> i\), \(M_{ik}=0\). Diagonal entries in \(N\) being zero implies that for \(k\leq i\), \(N_{ki}=0\). Therefore, \((MN)_{ii}=0\) for all \(1\leq i\leq n\). This proves \(MN\in I\). So 
\(I\) is an ideal in \(A\). Moreover, consider \(A/I\). For \(M_1,M_2\in A\), \(M_1-M_2\in I\) if and only if the diagonal entries of \(M_1\) and \(M_2\) are the same, namely 
\[(M_1)_{ii}=(M_2)_{ii}\]
for all \(1\leq i\leq n\). This means \(A/I\) can be viewed as the following set of diagonal matrices
\[\left\{ \begin{pmatrix}
    a_1& & &  \\ 
    &a_2& &  \\ 
    & & \ddots &  \\ 
    & & & a_n
\end{pmatrix}\mid a_1,a_2,\ldots,a_n\in \mathbb{F}\right\}.\]
The multiplication is given by 
\[\begin{pmatrix}
    a_1& & &  \\ 
    &a_2& &  \\ 
    & & \ddots &  \\ 
    & & & a_n
\end{pmatrix}\begin{pmatrix}
    b_1& & &  \\ 
    &b_2& &  \\ 
    & & \ddots &  \\ 
    & & & b_n
\end{pmatrix}=\begin{pmatrix}
    b_1& & &  \\ 
    &b_2& &  \\ 
    & & \ddots &  \\ 
    & & & b_n
\end{pmatrix}\begin{pmatrix}
    a_1& & &  \\ 
    &a_2& &  \\ 
    & & \ddots &  \\ 
    & & & a_n
\end{pmatrix}=\begin{pmatrix}
    a_1b_1& & &  \\ 
    &a_2b_2& &  \\ 
    & & \ddots &  \\ 
    & & & a_nb_n
\end{pmatrix}.\]
So we know that \(A/I\cong \mathbb{F}^n\) is a field. This proves that \(I\) is a maximal ideal in \(A\). If we can prove that every matrix in \(I\) is nilpotent, then by Proposition 16.3.16, we are done because \(J(A)\) contains a maximal ideal \(I\), then \(J(A)=I\). 
\begin{claim}
Every matrix \(N\in I\) is nilpotent. 
\end{claim}
\begin{claimproof}
We prove this by induction on \(n\). For \(n=2\), let \(a,b\in \mathbb{F}\), we have 
\[\begin{pmatrix}
    0&0\\ 
    a&0
\end{pmatrix}\begin{pmatrix}
    0&0\\ 
    b&0
\end{pmatrix}=\begin{pmatrix}
    0&0\\ 
    0&0
\end{pmatrix}.\]
For \(n\geq 3\), suppose we have proved the claim for \((n-1)\times (n-1)\) matrices. Let \(N,L\in I\) be two matrices. For \(1\leq i\leq n-1\), we know that the \((i+1,i)\)-entry of \(NL\) can be calculated as 
\[(NL)_{i+1,i}=\sum_{k=1}^{n}N_{i+1,k}L_{ki}.\]
\(N,L\in I\) implies that for \(i+1\leq k\), \(N_{i+1,k}=0\) and for \(k\leq i\), \(L_{ki}=0\). This proves that \((NL)_{i+1,i}=0\) for \(1\leq i\leq n-1\). This means \(NL\) can be written as the following form 
\[\begin{pmatrix}
    0 &\cdots&0\\ 
    &N'&\vdots\\ 
    & & 0
\end{pmatrix}\]
where \(N'\) is a \((n-1)\times (n-1)\) lower triangular matrix with diagonal entries zero. Now choose \(n\) even and large enough, \(N_1N_2\cdots N_n\in I\) can be written as 
\[(N_1N_2)\cdots (N_{n-1}N_n)\]
where each pair can be viewed as a \((n-1)\times (n-1)\) matrix. By our assumption, this must equal to \(0\).
\end{claimproof}
\end{solution}

\noindent\rule{7in}{2.8pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Exercise 16.3.22
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}{16.3.22}
Let \(A\) be a non-commutative finite dimensional algebra over \(\mathbb{C}\) such that the left regular module \(\leftindex_A A\) has length two. What can you say about \(A\)?
\end{problem}
\begin{solution}
\(A\) is finite dimensional over \(\mathbb{C}\), so \(A\) must be Artinian. Suppose \(J(A)=0\), by Theorem 16.3.21, \(A\) is left semisimple. By Wedderburn-Artin Theorem, \(A\) is isomorphic to 
\[M_{n_1}(\mathbb{C})\times\cdots\times M_{n_k}(\mathbb{C}).\]
Since \(A\) is non-commutative, so at least one of \(n_1,n_2,\ldots,n_k\) is bigger or equal to 2. Without loss of generality, we can assume \(n_1\geq 2\). By Proposition 16.2.6, we know that \(\mathbb{C}^2\) of the column vectors is the only 
simple \(M_2(\mathbb{C})\)-module up to isomorphism, so we have a composition series of length \(2\) for \(M_2(\mathbb{C})\) 
\[M_2(\mathbb{C})\supset \left\{ \begin{pmatrix}
0&*\\ 
0&*
\end{pmatrix} \right\}\supset 0.\]
Since \(A\) as a left regular module has length \(2\), so \(A\cong M_2(\mathbb{C})\). 

Now assume \(J(A)\neq 0\). Consider the following composition series of \(A\) as a left regular module
\[A\supset B\supset 0.\]
\(A/B\) being a simple \(A\)-module tells us that \(B\) must be a maximal ideal in \(A\). Suppose \(m\subset A\) is a maximal ideal, then \(m\cap B\) is an ideal in \(A\) and we have 
\[B\supset (m\cap B)\supset 0.\]
Because \(B\) is simple as a \(A\)-module, so \(m\cap B=0\) or \(m\cap B=B\). We have already assumed \(J(A)\) as an intersection of all maximal ideals is not zero, so \(m\cap B=B\). This means \(m=B\). So \(B\) is the unique maximal ideal in \(A\) and we have 
\(J(A)=B\). Note that \(J(A)\) is a simple \(A\)-module, by Exercise 14.1.23, \(J(A)\) is isomorphic to \(A/m\) for some maximal ideal in \(A\), and there is only one unique maximal ideal \(J(A)\), so we have 
\(A/J(A)\cong J(A)\) as simple \(A\)-modules. We know that \(J(A/J(A))=0\) by Proposition 16.3.6. \(A/J(A)\) is artinian and thus semisimple. Note that \(A/J(A)\) has length \(1\) and by Wedderburn-Artin theorem, we have 
\[J(A)\cong A/J(A)\cong \mathbb{C}.\]
This means \(A\cong \mathbb{C}^2\) and commutative. A contradiction. Therefore, the only possible case is that \(A\cong M_2(\mathbb{C})\) with \(J(A)=0\).  
\end{solution}

\noindent\rule{7in}{2.8pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Exercise 16.3.23
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}{16.3.23}
True or false? An artinian ring has a finite number of irreducible modules up to isomorphism.
\end{problem}
\begin{solution}
This is true. Suppose \(R\) is an Artinian ring. We have proved in Exercise 14.1.23 that any simple \(R\)-module is isomorphic to \(R/I\) where \(I\) is a maximal left ideal in \(R\). So we only need to that 
\(R\) has finitely many maximal left ideals up to isomorphism. Hopkins-Levitzki Theorem tells us that \(R\) is also Noetherian. So \(R\) as a left regular module has finite length. 
For every maximal ideal \(m\subset R\), we know that \(R/m\) is a field, so there exists a Jordan-H\"{o}lder series 
\[R=J_0\supset m\supset m_1\supset \cdots m_n=0.\]
By Jordan-H\"{o}lder Theorem, \(R/m\) must be one of the Jordan H\"{o}lder factors, and finite length implies there only exists finitely many Jordan-H\"{o}lder factors up to isomorphism. So we only have finitely many

\end{solution}

\noindent\rule{7in}{2.8pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Exercise 16.3.26
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}{16.3.26}
True or false? If \(R\) is an artinian ring having no non-zero nilpotent elements then \(R\) is a direct sum of division rings.
\end{problem}
\begin{solution}
This is true. \(R\) is artinian, by Lemma 16.3.17, \(J(R)\) must be nilpotent. But \(R\) does not contain any non-zero nilpotent element, so \(J(R)=0\). By Theorem 16.3.21, \(R\) is left semisimple, By Wedderburn-Artin Theorem, 
\(R\) is a direct sum of matrix rings 
\[M_{n_1}(D_1)\times \cdots \times M_{n_k}(D_k).\]
Suppose one of \(n_1,\ldots,n_k\geq 2\), without loss of generality \(n_1\geq 2\). We can pick an element \(A\in M_{n_1}(D_1)\) with only one nonzero entry at the left bottom corner, namely \((n,1)\)-entry. By calculation, we have \(A^2=0\). This contradicts that 
\(R\) does not have non-zero nilpotents, so \(n_1=\cdots=n_k=1\). Thus, \(R\) is a direct sum of division rings. 
\end{solution}

\noindent\rule{7in}{2.8pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Exercise 16.3.29
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}{16.3.29}
Let \(A\) be a finite dimensional algebra over \(\mathbb{C}\). For each \(a\in A\), consider the linear operator \(L_a:A\rightarrow A\), \(b\mapsto ab\). For all 
\(a,b\in A\), define \((a|b):=\tr(L_aL_b)\), the trace of the linear operator \(L_aL_b\).
\begin{enumerate}[(1)]
\item \((-|-)\) is a symmetric bilinear form on \(A\). 
\item The radical \(\Rad(-|-):=\left\{ a\in A\mid (a,b)=0\ \ \text{for}\ \ \text{all}\ \ b\in A \right\}\) is an ideal in \(A\). 
\item \(\Rad(-|-)=J(A)\).
\end{enumerate}
\end{problem}
\begin{solution}
\begin{enumerate}[(1)]
\item Let \(c_1,c_2\in \mathbb{C}\) and \(a_1,a_2\in A\). For any \(b\in A\) , we have \((c_1a_1+c_2a_2)b=c_1a_1b+c_2a_2b\). This proves that for any \(a\in A\), 
\begin{align*}
    L_a:A&\rightarrow A,\\ 
        b&\mapsto ab.
\end{align*}
is a \(\mathbb{C}\)-linear operator. Suppose \(A\) is a \(n\)-dimensional algebra over \(\mathbb{C}\). The operator \(L_a\) can be represented as a \(n\times n\) matrix with entries in \(\mathbb{C}\). 
\begin{claim}
For any\(a,b\in A\), we have \(\tr (L_aL_b)=\tr(L_bL_a)\) where \(\tr(L_aL_b)\) is the trace of the matrix product \(L_aL_b\). 
\end{claim}
\begin{claimproof}
By the previous discussion, we know that \(L_a\) can be written as a \(n\times n\) matrix \((a_{ij})_{1\leq i,j\leq n}\). Similarly, \(L_b=(b_{ij})_{1\leq i,j\leq n}\). Then the trace can be calculated as 
\begin{align*}
    \tr(L_aL_b)&=\tr(\sum_{k=1}^{n}a_{ik}b_{kj})\\ 
               &=\sum_{i=1}^{n}\sum_{k=1}^{n}a_{ik}b_{ki}\\ 
               &=\sum_{i=1}^{n}\sum_{k=1}^{n}b_{ki}a_{ik}\\ 
               &=\sum_{k=1}^{n}\sum_{i=1}^{n}b_{ki}a_{ik}\\ 
               &=\tr(L_bL_a)
\end{align*}
\end{claimproof}

For any \(a_1,a_2,b\in A\) and \(c_1,c_2\in \mathbb{C}\), by linearity of \(L_a\), we have 
\[L_{c_1a_1+c_2a_2}=c_1L_{a_1}+c_2L_{a_2}.\]
Note that the trace of a matrix is also a \(\mathbb{C}\)-linear operator, so we have 
\[(c_1a_1+c_2a_2|b)=\tr(L_{c_1a_1+c_2a_2}L_b)=c_1(a_1|b)+c_2(a_2|b).\]
From the above claim, we know that \((-|-)\) is also symmetric, so \((-|-)\) is a symmetric bilinear form.
\item For any \(a\in \Rad(-|-)\) and \(b,c\in A\), let \(L_a\), \(L_b\), \(L_c\) be the corresponding \(n\times n\) matrices over \(\mathbb{C}\). Note that \(L_cL_b=L_{cb}\) is also a linear operator related to the element \(cb\in A\), so we have 
\[0=(a|cb)=\tr(L_aL_{cb})=\tr(L_aL_cL_b)=\tr(L_{ac}L_b)=(ac|b)\] 
by definition of \(\Rad(-|-)\) and associativity of matrix multiplication. This proves that \(ac\in \Rad(-|-)\) and \(\Rad(-|-)\) is a right ideal of \(A\). On the other hand, from the claim we know that 
\[0=(a|bc)=\tr(L_a(L_{bc}))=\tr((L_aL_b)L_c)=\tr(L_c(L_aL_b))=\tr(L_{ca}L_b)=(ca|b).\]
This proves that \(ca\in \Rad(-|-)\) and \(\Rad(-|-)\) is a left ideal of \(A\). Thus, \(\Rad(-|-)\) is a two sided ideal of \(A\). 
\item Let \(a\in J(A)\). We need to show that \((a|b)=0\) for all \(b\in A\). \(A\) being a finite dimensional algebra over \(\mathbb{C}\) implies that \(A\) is artinian. By Lemma 16.3.17, \(J(A)\) is a nilpotent ideal of \(A\). So \(ab\in J(A)\) is nilpotent and the matrix 
\(L_{ab}=L_aL_b\) is nilpotent. There exists \(m\in \mathbb{Z}_{>0}\) such that \((L_{ab})^m=0\). The monomial \(x^m\) divides the minimal polymial of \(L_{ab}\) and since the minimal polynomial divides the characteristic polynomial, we can conclude that the characteristic polynomial of 
\(L_{ab}\) is \(x^n\). All the eigenvalues of \(L_{ab}\) is zero and since the trace can be calculated as the sum of all eigenvalues, we know that \(\tr(L_{ab})=\tr(L_aL_b)=0\). This proves that \(J(A)\subset \Rad(-|-)\). 

On the other hand, let \(a\in \Rad(-|-)\). For any \(b\in A\) and \(k\in \mathbb{Z}_{>0}\), we have 
\[\tr((L_{ab})^k)=\tr(L_aL_b\cdots L_aL_b)=(a|bab\cdots)=0.\]
\begin{claim}
Let \(M\) be an \(n\times n\) matrix over \(\mathbb{C}\). If \(\tr(M^k)=0\) for \(k=1,2,\ldots,n\). Then \(M\) is a nilpotent matrix.
\end{claim}
\begin{claimproof}
Assume the opposite, \(M\) is not nilpotent. Note that over \(\mathbb{C}\) \(M\) must have \(n\) eigenvalues. If \(M\) is not nilpotent, then \(M\) must have at least one nonzero eigenvalue (otherwise the characteristic polynomial of \(M\) will be \(x^n\) and \(M\) is nilpotent). Suppose 
\(\lambda_1,\lambda_2,\ldots,\lambda_r\) are different nonzero eigenvalues of \(M\) with multiplicity \(n_1,n_2,\ldots,n_r\) for \(r\geq 1\). For any \(1\leq i\leq r\) and \(1\leq k\leq n\), note that 
\[M^kv_i=M^{k-1}\lambda_iv_i=\lambda_iM^{k-1}v_i=\cdots=\lambda_i^kv_i.\]
where \(v_i\) is the corresponding eigenvector to the eigenvalue \(\lambda_i\). This tells us that \(M^k\) has nonzero eigenvalue \(\lambda_1^k,\ldots,\lambda_r^k\) with multiplicity \(n_1,\ldots,n_r\). From the assumeption, we know that 
\[0=\tr(M)=\tr(M^2)=\cdots=\tr(M^n).\]
This gives us \(n\) equations 
\begin{align*}
    n_1\lambda_1+n_2\lambda_2+\cdots +n_r\lambda_r&=0,\\
    n_1\lambda_1^2+n_2\lambda_2^2+\cdots+n_r\lambda_r^2&=0, \\
    \ldots\\ 
    n_1\lambda_1^n+n_2\lambda_2^n+\cdots+n_r\lambda_r^n&=0.
\end{align*}
This can be rewritten in the matrix form 
\[\begin{pmatrix}
    \lambda_1&\lambda_2&\cdots&\lambda_r\\ 
    \lambda_1^2&\lambda_2^2&\cdots&\lambda_r^2\\ 
    \vdots&\vdots&&\vdots\\ 
    \lambda_1^n&\lambda_2^n&\cdots&\lambda_r^n
\end{pmatrix}\begin{pmatrix}
    n_1\\ 
    n_2\\ 
    \vdots\\ 
    n_r
\end{pmatrix}=\begin{pmatrix}
    0\\ 
    0\\ 
    \vdots\\ 
    0
\end{pmatrix}.\]
This can be viewed as a system of \(n\) equations and the coefficient matrix is denoted by \(N\). Note that by Exercise 4.3.13 (Vandermonde determinant), we have 
\[\det N=\lambda_1\lambda_2\cdots\lambda_r\det \begin{pmatrix}
    1&1&\cdots&1\\ 
    \lambda_1&\lambda_2&\cdots &\lambda_r\\ 
    \vdots&\vdots&&\vdots\\ 
    \lambda_1^{n-1}&\lambda_2^{n-1}&\cdots&\lambda_r^{n-1}
\end{pmatrix}=\lambda_1\lambda_2\cdots\lambda_r\prod_{1\leq i<j\leq n}(\lambda_i-\lambda_j).\]
Recall that we choose \(\lambda_1,\ldots,\lambda_r\) to be nonzero and different from each other, so \(\det N\neq 0\) and \(N\) is invertible. This implies the system of equations has a unqiue solution 
\[n_1=n_2=\cdots=n_r=0.\]
This contradicts our assumption \(M\) has nonzero eigenvalues. So \(M\) must be nilpotent. 
\end{claimproof}

From the claim we know that \((L_{ab})^n=0\) as a matrix. Similarly for \(L_{ba}\), we have 
\begin{align*}
\tr(L_{ba})&=\tr(L_bL_a)=\tr(L_aL_b)=0,\\ 
\tr((L_{ba})^2)&=\tr((L_bL_aL_b)L_a)=\tr(L_a(L_bL_aL_b))=0,\\ 
\cdots\\ 
\tr((L_{ba})^n)&=\tr((L_{ba})^{n-1}L_bL_a)=\tr(L_a(L_{ba})^{n-1}L_b)=0.
\end{align*} 
By the claim, \((L_{ba})^n=0\). So \(\Rad(-|-)\) is a two-sided ideal where every element is nilpotent. For \(I_n+L_{ab}\in M_n(\mathbb{C})\), we have 
\[(I_n-L_{ab}+(L_ab)^2-\cdots+(-1)^{n-1}(L_{ab})^{n-1})(I_n+L_{ab})=I_n+(L_{ab})^n=I_n.\]
So \(I_n+L_{ab}\) is a unit. Same for \(I_n+L_{ba}\). By Propostion 16.3.8, since \(J(A)\) is the largest two-sided ideal containing such elements, we have \(ab\in J(A)\) and \(ba\in J(A)\). We have 
proved \(\Rad(-|-)\subset J(A)\) and therefore, \(J(A)=\Rad(-|-)\).
\end{enumerate}
\end{solution}


\end{document}